{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "complete-capital",
   "metadata": {},
   "source": [
    "# Path setup & import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "packed-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "root_path = '../../' # path to project root\n",
    "sys.path.append('{}/code'.format(root_path))\n",
    "sys.path.append('{}/code/core'.format(root_path))\n",
    "sys.path.append('{}/code/datasets/'.format(root_path))\n",
    "sys.path.insert(0,'{}/code/ptranking'.format(root_path))\n",
    "\n",
    "from core.ranking_utils import *\n",
    "from core.mallows import *\n",
    "from core.ws_ranking import *\n",
    "from core.ws_real_workflow import * \n",
    "from datasets.imdb_tmdb_dataset import * \n",
    "from datasets.basic_clmn_dataset import * \n",
    "from core.labelling.feature_lf import *\n",
    "from ptranking_wrapper import PtrankingWrapper\n",
    "import datasets_factory \n",
    "import numpy as np \n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-newcastle",
   "metadata": {},
   "source": [
    "# Read config & basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "agreed-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = '{}/configs/modified-mslr-web10k_ranking_experiment.yaml'.format(root_path)\n",
    "\n",
    "with open(config_file_path,'r') as conf_file:\n",
    "    conf = yaml.full_load(conf_file)\n",
    "    conf['project_root'] = root_path \n",
    "\n",
    "data_conf = conf['data_conf']\n",
    "weak_sup_conf = conf['weak_sup_conf'] # For partial ranking experiments, we should give\n",
    "l2r_training_conf = conf['l2r_training_conf']\n",
    "data_conf['project_root'] = root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "relative-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seed in range(5):\n",
    "    \n",
    "#     save_path = os.path.join(root_path, 'data/MSLR-WEB10K/True_5')\n",
    "#     file_train = 'train.npz'\n",
    "#     file_test = 'test.npz'\n",
    "\n",
    "#     train = np.load(os.path.join(save_path, file_train))\n",
    "#     test = np.load(os.path.join(save_path, file_test))\n",
    "#     X_train, Y_train, qid_train = train['X'], train['Y'], train['qid']\n",
    "#     X_test, Y_test, qid_test = test['X'], test['Y'], test['qid']\n",
    "\n",
    "#     # Weak supervision\n",
    "#     d = X_train.shape[1]\n",
    "#     r_utils = RankingUtils(d)\n",
    "#     dummy_lf = FeatureRankingLF(rank_on_feature=0, d=d, highest_first=False)\n",
    "#     true_ranking = dummy_lf.apply_mat(np.concatenate((np.expand_dims(Y_train, axis=-1), np.expand_dims(Y_test, axis=-1))))\n",
    "\n",
    "#     df = pd.DataFrame()\n",
    "#     feature_list = [0, 5, 95, 101, 106, 111, 116, 121, 133]\n",
    "#     L_ = []\n",
    "#     for feature in feature_list:\n",
    "#         lf = FeatureRankingLF(rank_on_feature=feature, d=d, highest_first=True)\n",
    "#         wl = lf.apply_mat(np.concatenate((X_train, X_test)))\n",
    "#         kt = r_utils.mean_kt_distance(true_ranking, wl)\n",
    "#         df = df.append(\n",
    "#         {\n",
    "#             'feature': feature,\n",
    "#             'kt': kt\n",
    "#         }, ignore_index=True)\n",
    "#         L_.append(wl)\n",
    "\n",
    "#     display(df)\n",
    "\n",
    "#     L = []\n",
    "#     for data_idx in range(len(L_[0])):\n",
    "#         L_row = []\n",
    "#         for wl_idx in range(len(L_)):\n",
    "#             L_row.append(L_[wl_idx][data_idx])\n",
    "#         L.append(L_row)\n",
    "\n",
    "#     wsr = WeakSupRanking(r_utils)\n",
    "#     wsr.train(weak_sup_conf, L)\n",
    "\n",
    "#     m = len(L[0])\n",
    "#     lst_pi_hat = wsr.infer_ranking(weak_sup_conf, L, numLFs=m)\n",
    "#     kt = r_utils.mean_kt_distance(true_ranking, lst_pi_hat)\n",
    "#     print('inference kt:', kt)\n",
    "    \n",
    "#     ptwrapper = PtrankingWrapper(data_conf=data_conf, weak_sup_conf=weak_sup_conf,\n",
    "#                                  l2r_training_conf=l2r_training_conf, result_path=conf['results_path'],\n",
    "#                                  wl_kt_distance = kt)\n",
    "\n",
    "#     Y_train = ranking_to_score(lst_pi_hat, d=d, highest_first=False)[:X_train.shape[0]]\n",
    "#     ptwrapper.set_data(X_train=X_train, X_test=X_test,\n",
    "#                       Y_train=Y_train, Y_test=Y_test)\n",
    "#     model = ptwrapper.get_model()\n",
    "#     result = ptwrapper.train_model(model, IR=True, verbose=1)\n",
    "#     result_path = f'results/Selected_{seed}.pickle'\n",
    "#     with open(result_path, 'wb') as f:\n",
    "#         pickle.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "royal-abortion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>kt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.135275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.121683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.126483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106.0</td>\n",
       "      <td>0.131769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111.0</td>\n",
       "      <td>0.124649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>116.0</td>\n",
       "      <td>0.123894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.123409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.153398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature        kt\n",
       "0      0.0  0.135275\n",
       "1      5.0  0.135275\n",
       "2     95.0  0.121683\n",
       "3    101.0  0.126483\n",
       "4    106.0  0.131769\n",
       "5    111.0  0.124649\n",
       "6    116.0  0.123894\n",
       "7    121.0  0.123409\n",
       "8    133.0  0.153398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference kt: 0.11699029126213592\n",
      "Training data shape, X_train.shape (1375, 5, 136) Y_train.shape torch.Size([1375, 5])\n",
      "set_and_load_data in LTREvaluator\n",
      "(1375, 5, 136) torch.Size([1375, 5]) (1375,)\n",
      "data_dict {'data_id': 'MODIFIED_MSLR_WEB10K', 'dir_data': 'data/MSLR-WEB10K/processed/default', 'min_docs': 10, 'min_rele': 1, 'scale_data': False, 'scaler_id': None, 'scaler_level': None, 'train_presort': True, 'validation_presort': True, 'test_presort': True, 'train_batch_size': 64, 'validation_batch_size': 1, 'test_batch_size': 1, 'unknown_as_zero': False, 'binary_rele': False, 'num_features': 136, 'has_comment': False, 'label_type': <LABEL_TYPE.Permutation: 2>, 'max_rele_level': None, 'fold_num': 1}\n",
      "data_dict {'data_id': 'MODIFIED_MSLR_WEB10K', 'dir_data': 'data/MSLR-WEB10K/processed/default', 'min_docs': 10, 'min_rele': 1, 'scale_data': False, 'scaler_id': None, 'scaler_level': None, 'train_presort': True, 'validation_presort': True, 'test_presort': True, 'train_batch_size': 64, 'validation_batch_size': 1, 'test_batch_size': 1, 'unknown_as_zero': False, 'binary_rele': False, 'num_features': 136, 'has_comment': False, 'label_type': <LABEL_TYPE.Permutation: 2>, 'max_rele_level': None, 'fold_num': 1}\n",
      "Sequential(\n",
      "  (FeatureBN): BatchNorm1d(136, eps=1e-05, momentum=1.0, affine=True, track_running_stats=False)\n",
      "  (L_1): Linear(in_features=136, out_features=30, bias=True)\n",
      "  (BN_1): BatchNorm1d(30, eps=1e-05, momentum=1.0, affine=True, track_running_stats=False)\n",
      "  (ACT_1): ReLU()\n",
      "  (DR_2): Dropout(p=0.01, inplace=False)\n",
      "  (L_2): Linear(in_features=30, out_features=30, bias=True)\n",
      "  (BN_2): BatchNorm1d(30, eps=1e-05, momentum=1.0, affine=True, track_running_stats=False)\n",
      "  (ACT_2): ReLU()\n",
      "  (L_3): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n",
      "epoch 0, loss [1130.4878], train tau 0.2546178102493286, test_tau 0.39519834518432617,train_ndcg@1 tensor([0.7765]), test_ndcg@1 tensor([0.6707])train_p@1 tensor([0.9651]), test_p@1, tensor([0.7495])\n",
      "epoch 1, loss [1028.1748], train tau 0.2421087622642517, test_tau 0.38058456778526306,train_ndcg@1 tensor([0.7876]), test_ndcg@1 tensor([0.7056])train_p@1 tensor([0.9658]), test_p@1, tensor([0.7370])\n",
      "epoch 2, loss [997.0835], train tau 0.22901788353919983, test_tau 0.37933194637298584,train_ndcg@1 tensor([0.8033]), test_ndcg@1 tensor([0.7208])train_p@1 tensor([0.9658]), test_p@1, tensor([0.7328])\n",
      "epoch 3, loss [980.7608], train tau 0.22145387530326843, test_tau 0.3778705596923828,train_ndcg@1 tensor([0.8125]), test_ndcg@1 tensor([0.7218])train_p@1 tensor([0.9702]), test_p@1, tensor([0.7349])\n",
      "epoch 4, loss [965.25494], train tau 0.21447214484214783, test_tau 0.3764091730117798,train_ndcg@1 tensor([0.8222]), test_ndcg@1 tensor([0.7182])train_p@1 tensor([0.9724]), test_p@1, tensor([0.7328])\n",
      "epoch 5, loss [953.81384], train tau 0.21185365319252014, test_tau 0.3768267035484314,train_ndcg@1 tensor([0.8275]), test_ndcg@1 tensor([0.7265])train_p@1 tensor([0.9782]), test_p@1, tensor([0.7349])\n",
      "epoch 6, loss [939.8528], train tau 0.20719900727272034, test_tau 0.3766179382801056,train_ndcg@1 tensor([0.8291]), test_ndcg@1 tensor([0.7203])train_p@1 tensor([0.9789]), test_p@1, tensor([0.7411])\n",
      "epoch 7, loss [928.8621], train tau 0.2046533226966858, test_tau 0.3810020685195923,train_ndcg@1 tensor([0.8315]), test_ndcg@1 tensor([0.7129])train_p@1 tensor([0.9796]), test_p@1, tensor([0.7244])\n",
      "epoch 8, loss [921.2562], train tau 0.2006535530090332, test_tau 0.37536534667015076,train_ndcg@1 tensor([0.8364]), test_ndcg@1 tensor([0.7223])train_p@1 tensor([0.9789]), test_p@1, tensor([0.7203])\n",
      "epoch 9, loss [911.7519], train tau 0.2008720338344574, test_tau 0.3824634552001953,train_ndcg@1 tensor([0.8289]), test_ndcg@1 tensor([0.7082])train_p@1 tensor([0.9782]), test_p@1, tensor([0.7286])\n",
      "The experiment result is saved in ../../tmp/results/MSLR-WEB10K/default/result_summary.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>kt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.135275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.121683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.126483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106.0</td>\n",
       "      <td>0.131769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111.0</td>\n",
       "      <td>0.124649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>116.0</td>\n",
       "      <td>0.123894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.123409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.153398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature        kt\n",
       "0      0.0  0.135275\n",
       "1      5.0  0.135275\n",
       "2     95.0  0.121683\n",
       "3    101.0  0.126483\n",
       "4    106.0  0.131769\n",
       "5    111.0  0.124649\n",
       "6    116.0  0.123894\n",
       "7    121.0  0.123409\n",
       "8    133.0  0.153398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference kt: 0.11699029126213592\n",
      "Training data shape, X_train.shape (1375, 5, 136) Y_train.shape torch.Size([1375, 5])\n",
      "set_and_load_data in LTREvaluator\n",
      "(1375, 5, 136) torch.Size([1375, 5]) (1375,)\n",
      "data_dict {'data_id': 'MODIFIED_MSLR_WEB10K', 'dir_data': 'data/MSLR-WEB10K/processed/default', 'min_docs': 10, 'min_rele': 1, 'scale_data': False, 'scaler_id': None, 'scaler_level': None, 'train_presort': True, 'validation_presort': True, 'test_presort': True, 'train_batch_size': 64, 'validation_batch_size': 1, 'test_batch_size': 1, 'unknown_as_zero': False, 'binary_rele': False, 'num_features': 136, 'has_comment': False, 'label_type': <LABEL_TYPE.Permutation: 2>, 'max_rele_level': None, 'fold_num': 1}\n",
      "data_dict {'data_id': 'MODIFIED_MSLR_WEB10K', 'dir_data': 'data/MSLR-WEB10K/processed/default', 'min_docs': 10, 'min_rele': 1, 'scale_data': False, 'scaler_id': None, 'scaler_level': None, 'train_presort': True, 'validation_presort': True, 'test_presort': True, 'train_batch_size': 64, 'validation_batch_size': 1, 'test_batch_size': 1, 'unknown_as_zero': False, 'binary_rele': False, 'num_features': 136, 'has_comment': False, 'label_type': <LABEL_TYPE.Permutation: 2>, 'max_rele_level': None, 'fold_num': 1}\n",
      "Sequential(\n",
      "  (FeatureBN): BatchNorm1d(136, eps=1e-05, momentum=1.0, affine=True, track_running_stats=False)\n",
      "  (L_1): Linear(in_features=136, out_features=30, bias=True)\n",
      "  (BN_1): BatchNorm1d(30, eps=1e-05, momentum=1.0, affine=True, track_running_stats=False)\n",
      "  (ACT_1): ReLU()\n",
      "  (DR_2): Dropout(p=0.01, inplace=False)\n",
      "  (L_2): Linear(in_features=30, out_features=30, bias=True)\n",
      "  (BN_2): BatchNorm1d(30, eps=1e-05, momentum=1.0, affine=True, track_running_stats=False)\n",
      "  (ACT_2): ReLU()\n",
      "  (L_3): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n",
      "epoch 0, loss [1101.1768], train tau 0.25250938534736633, test_tau 0.3910229802131653,train_ndcg@1 tensor([0.7764]), test_ndcg@1 tensor([0.7176])train_p@1 tensor([0.9665]), test_p@1, tensor([0.7557])\n",
      "epoch 1, loss [1024.5897], train tau 0.23556336760520935, test_tau 0.3736951947212219,train_ndcg@1 tensor([0.7920]), test_ndcg@1 tensor([0.7302])train_p@1 tensor([0.9760]), test_p@1, tensor([0.7307])\n",
      "epoch 2, loss [995.68195], train tau 0.22959959506988525, test_tau 0.3713987469673157,train_ndcg@1 tensor([0.7989]), test_ndcg@1 tensor([0.7484])train_p@1 tensor([0.9745]), test_p@1, tensor([0.7411])\n",
      "epoch 3, loss [976.0021], train tau 0.22196310758590698, test_tau 0.37432149052619934,train_ndcg@1 tensor([0.8065]), test_ndcg@1 tensor([0.7406])train_p@1 tensor([0.9753]), test_p@1, tensor([0.7620])\n",
      "epoch 4, loss [959.45776], train tau 0.21607175469398499, test_tau 0.3678497076034546,train_ndcg@1 tensor([0.8165]), test_ndcg@1 tensor([0.7547])train_p@1 tensor([0.9804]), test_p@1, tensor([0.7599])\n",
      "epoch 5, loss [943.90356], train tau 0.21068957448005676, test_tau 0.36597076058387756,train_ndcg@1 tensor([0.8207]), test_ndcg@1 tensor([0.7401])train_p@1 tensor([0.9796]), test_p@1, tensor([0.7495])\n",
      "epoch 6, loss [930.94586], train tau 0.20778056979179382, test_tau 0.3770354986190796,train_ndcg@1 tensor([0.8273]), test_ndcg@1 tensor([0.7364])train_p@1 tensor([0.9789]), test_p@1, tensor([0.7516])\n",
      "epoch 7, loss [917.5315], train tau 0.20014381408691406, test_tau 0.376617968082428,train_ndcg@1 tensor([0.8273]), test_ndcg@1 tensor([0.7276])train_p@1 tensor([0.9847]), test_p@1, tensor([0.7495])\n",
      "epoch 8, loss [904.18115], train tau 0.19294407963752747, test_tau 0.3716075122356415,train_ndcg@1 tensor([0.8398]), test_ndcg@1 tensor([0.7370])train_p@1 tensor([0.9796]), test_p@1, tensor([0.7453])\n",
      "epoch 9, loss [894.6121], train tau 0.19323495030403137, test_tau 0.3774530291557312,train_ndcg@1 tensor([0.8413]), test_ndcg@1 tensor([0.7307])train_p@1 tensor([0.9775]), test_p@1, tensor([0.7432])\n",
      "The experiment result is saved in ../../tmp/results/MSLR-WEB10K/default/result_summary.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>kt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.135275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.121683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.126483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106.0</td>\n",
       "      <td>0.131769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111.0</td>\n",
       "      <td>0.124649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>116.0</td>\n",
       "      <td>0.123894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.123409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.153398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature        kt\n",
       "0      0.0  0.135275\n",
       "1      5.0  0.135275\n",
       "2     95.0  0.121683\n",
       "3    101.0  0.126483\n",
       "4    106.0  0.131769\n",
       "5    111.0  0.124649\n",
       "6    116.0  0.123894\n",
       "7    121.0  0.123409\n",
       "8    133.0  0.153398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference kt: 0.11699029126213592\n",
      "Training data shape, X_train.shape (1375, 5, 136) Y_train.shape torch.Size([1375, 5])\n",
      "set_and_load_data in LTREvaluator\n",
      "(1375, 5, 136) torch.Size([1375, 5]) (1375,)\n",
      "data_dict {'data_id': 'MODIFIED_MSLR_WEB10K', 'dir_data': 'data/MSLR-WEB10K/processed/default', 'min_docs': 10, 'min_rele': 1, 'scale_data': False, 'scaler_id': None, 'scaler_level': None, 'train_presort': True, 'validation_presort': True, 'test_presort': True, 'train_batch_size': 64, 'validation_batch_size': 1, 'test_batch_size': 1, 'unknown_as_zero': False, 'binary_rele': False, 'num_features': 136, 'has_comment': False, 'label_type': <LABEL_TYPE.Permutation: 2>, 'max_rele_level': None, 'fold_num': 1}\n",
      "data_dict {'data_id': 'MODIFIED_MSLR_WEB10K', 'dir_data': 'data/MSLR-WEB10K/processed/default', 'min_docs': 10, 'min_rele': 1, 'scale_data': False, 'scaler_id': None, 'scaler_level': None, 'train_presort': True, 'validation_presort': True, 'test_presort': True, 'train_batch_size': 64, 'validation_batch_size': 1, 'test_batch_size': 1, 'unknown_as_zero': False, 'binary_rele': False, 'num_features': 136, 'has_comment': False, 'label_type': <LABEL_TYPE.Permutation: 2>, 'max_rele_level': None, 'fold_num': 1}\n",
      "Sequential(\n",
      "  (FeatureBN): BatchNorm1d(136, eps=1e-05, momentum=1.0, affine=True, track_running_stats=False)\n",
      "  (L_1): Linear(in_features=136, out_features=30, bias=True)\n",
      "  (BN_1): BatchNorm1d(30, eps=1e-05, momentum=1.0, affine=True, track_running_stats=False)\n",
      "  (ACT_1): ReLU()\n",
      "  (DR_2): Dropout(p=0.01, inplace=False)\n",
      "  (L_2): Linear(in_features=30, out_features=30, bias=True)\n",
      "  (BN_2): BatchNorm1d(30, eps=1e-05, momentum=1.0, affine=True, track_running_stats=False)\n",
      "  (ACT_2): ReLU()\n",
      "  (L_3): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n",
      "epoch 0, loss [1114.176], train tau 0.251636803150177, test_tau 0.3908141851425171,train_ndcg@1 tensor([0.7807]), test_ndcg@1 tensor([0.7145])train_p@1 tensor([0.9695]), test_p@1, tensor([0.7620])\n",
      "epoch 1, loss [1027.9917], train tau 0.24079939723014832, test_tau 0.38392484188079834,train_ndcg@1 tensor([0.7853]), test_ndcg@1 tensor([0.7171])train_p@1 tensor([0.9629]), test_p@1, tensor([0.7307])\n",
      "epoch 2, loss [1002.0419], train tau 0.23032653331756592, test_tau 0.3774530291557312,train_ndcg@1 tensor([0.8011]), test_ndcg@1 tensor([0.7411])train_p@1 tensor([0.9680]), test_p@1, tensor([0.7390])\n",
      "epoch 3, loss [985.7999], train tau 0.22654470801353455, test_tau 0.37515658140182495,train_ndcg@1 tensor([0.8027]), test_ndcg@1 tensor([0.7401])train_p@1 tensor([0.9760]), test_p@1, tensor([0.7223])\n",
      "epoch 4, loss [965.3009], train tau 0.22247228026390076, test_tau 0.37473905086517334,train_ndcg@1 tensor([0.8147]), test_ndcg@1 tensor([0.7411])train_p@1 tensor([0.9760]), test_p@1, tensor([0.7370])\n",
      "epoch 5, loss [950.0304], train tau 0.21250802278518677, test_tau 0.3759916424751282,train_ndcg@1 tensor([0.8242]), test_ndcg@1 tensor([0.7364])train_p@1 tensor([0.9818]), test_p@1, tensor([0.7370])\n",
      "epoch 6, loss [936.4825], train tau 0.2049444615840912, test_tau 0.3722338080406189,train_ndcg@1 tensor([0.8333]), test_ndcg@1 tensor([0.7385])train_p@1 tensor([0.9804]), test_p@1, tensor([0.7244])\n",
      "epoch 7, loss [927.1166], train tau 0.2033441960811615, test_tau 0.37160754203796387,train_ndcg@1 tensor([0.8307]), test_ndcg@1 tensor([0.7469])train_p@1 tensor([0.9811]), test_p@1, tensor([0.7390])\n",
      "epoch 8, loss [914.73035], train tau 0.20087149739265442, test_tau 0.3713987469673157,train_ndcg@1 tensor([0.8373]), test_ndcg@1 tensor([0.7505])train_p@1 tensor([0.9796]), test_p@1, tensor([0.7370])\n",
      "epoch 9, loss [902.70056], train tau 0.1958533525466919, test_tau 0.3730688989162445,train_ndcg@1 tensor([0.8398]), test_ndcg@1 tensor([0.7510])train_p@1 tensor([0.9855]), test_p@1, tensor([0.7286])\n",
      "The experiment result is saved in ../../tmp/results/MSLR-WEB10K/default/result_summary.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>kt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.135275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.121683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.126483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106.0</td>\n",
       "      <td>0.131769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111.0</td>\n",
       "      <td>0.124649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>116.0</td>\n",
       "      <td>0.123894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.123409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.153398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature        kt\n",
       "0      0.0  0.135275\n",
       "1      5.0  0.135275\n",
       "2     95.0  0.121683\n",
       "3    101.0  0.126483\n",
       "4    106.0  0.131769\n",
       "5    111.0  0.124649\n",
       "6    116.0  0.123894\n",
       "7    121.0  0.123409\n",
       "8    133.0  0.153398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference kt: 0.11699029126213592\n",
      "Training data shape, X_train.shape (1375, 5, 136) Y_train.shape torch.Size([1375, 5])\n",
      "set_and_load_data in LTREvaluator\n",
      "(1375, 5, 136) torch.Size([1375, 5]) (1375,)\n",
      "data_dict {'data_id': 'MODIFIED_MSLR_WEB10K', 'dir_data': 'data/MSLR-WEB10K/processed/default', 'min_docs': 10, 'min_rele': 1, 'scale_data': False, 'scaler_id': None, 'scaler_level': None, 'train_presort': True, 'validation_presort': True, 'test_presort': True, 'train_batch_size': 64, 'validation_batch_size': 1, 'test_batch_size': 1, 'unknown_as_zero': False, 'binary_rele': False, 'num_features': 136, 'has_comment': False, 'label_type': <LABEL_TYPE.Permutation: 2>, 'max_rele_level': None, 'fold_num': 1}\n",
      "data_dict {'data_id': 'MODIFIED_MSLR_WEB10K', 'dir_data': 'data/MSLR-WEB10K/processed/default', 'min_docs': 10, 'min_rele': 1, 'scale_data': False, 'scaler_id': None, 'scaler_level': None, 'train_presort': True, 'validation_presort': True, 'test_presort': True, 'train_batch_size': 64, 'validation_batch_size': 1, 'test_batch_size': 1, 'unknown_as_zero': False, 'binary_rele': False, 'num_features': 136, 'has_comment': False, 'label_type': <LABEL_TYPE.Permutation: 2>, 'max_rele_level': None, 'fold_num': 1}\n",
      "Sequential(\n",
      "  (FeatureBN): BatchNorm1d(136, eps=1e-05, momentum=1.0, affine=True, track_running_stats=False)\n",
      "  (L_1): Linear(in_features=136, out_features=30, bias=True)\n",
      "  (BN_1): BatchNorm1d(30, eps=1e-05, momentum=1.0, affine=True, track_running_stats=False)\n",
      "  (ACT_1): ReLU()\n",
      "  (DR_2): Dropout(p=0.01, inplace=False)\n",
      "  (L_2): Linear(in_features=30, out_features=30, bias=True)\n",
      "  (BN_2): BatchNorm1d(30, eps=1e-05, momentum=1.0, affine=True, track_running_stats=False)\n",
      "  (ACT_2): ReLU()\n",
      "  (L_3): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n",
      "epoch 0, loss [1107.081], train tau 0.25687289237976074, test_tau 0.3883090019226074,train_ndcg@1 tensor([0.7775]), test_ndcg@1 tensor([0.7239])train_p@1 tensor([0.9607]), test_p@1, tensor([0.7328])\n",
      "epoch 1, loss [1022.98346], train tau 0.23970884084701538, test_tau 0.38079333305358887,train_ndcg@1 tensor([0.7907]), test_ndcg@1 tensor([0.7328])train_p@1 tensor([0.9665]), test_p@1, tensor([0.7307])\n",
      "epoch 2, loss [989.59393], train tau 0.22879937291145325, test_tau 0.37494778633117676,train_ndcg@1 tensor([0.8040]), test_ndcg@1 tensor([0.7375])train_p@1 tensor([0.9716]), test_p@1, tensor([0.7098])\n",
      "epoch 3, loss [970.4785], train tau 0.2231265902519226, test_tau 0.37515658140182495,train_ndcg@1 tensor([0.8155]), test_ndcg@1 tensor([0.7312])train_p@1 tensor([0.9673]), test_p@1, tensor([0.7265])\n",
      "epoch 4, loss [954.5195], train tau 0.2147631049156189, test_tau 0.37118998169898987,train_ndcg@1 tensor([0.8191]), test_ndcg@1 tensor([0.7495])train_p@1 tensor([0.9760]), test_p@1, tensor([0.7244])\n",
      "epoch 5, loss [935.9351], train tau 0.21185368299484253, test_tau 0.3732776641845703,train_ndcg@1 tensor([0.8235]), test_ndcg@1 tensor([0.7479])train_p@1 tensor([0.9709]), test_p@1, tensor([0.7119])\n",
      "epoch 6, loss [927.56036], train tau 0.20269012451171875, test_tau 0.3674321472644806,train_ndcg@1 tensor([0.8362]), test_ndcg@1 tensor([0.7390])train_p@1 tensor([0.9767]), test_p@1, tensor([0.7098])\n",
      "epoch 7, loss [914.51886], train tau 0.20341727137565613, test_tau 0.3726513385772705,train_ndcg@1 tensor([0.8331]), test_ndcg@1 tensor([0.7223])train_p@1 tensor([0.9782]), test_p@1, tensor([0.7140])\n",
      "epoch 8, loss [904.8008], train tau 0.1975993812084198, test_tau 0.3720250725746155,train_ndcg@1 tensor([0.8418]), test_ndcg@1 tensor([0.7469])train_p@1 tensor([0.9796]), test_p@1, tensor([0.7119])\n",
      "epoch 9, loss [891.3137], train tau 0.19570788741111755, test_tau 0.3728601336479187,train_ndcg@1 tensor([0.8451]), test_ndcg@1 tensor([0.7307])train_p@1 tensor([0.9753]), test_p@1, tensor([0.7203])\n",
      "The experiment result is saved in ../../tmp/results/MSLR-WEB10K/default/result_summary.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>kt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.135275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.121683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.126483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106.0</td>\n",
       "      <td>0.131769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111.0</td>\n",
       "      <td>0.124649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>116.0</td>\n",
       "      <td>0.123894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.123409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.153398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature        kt\n",
       "0      0.0  0.135275\n",
       "1      5.0  0.135275\n",
       "2     95.0  0.121683\n",
       "3    101.0  0.126483\n",
       "4    106.0  0.131769\n",
       "5    111.0  0.124649\n",
       "6    116.0  0.123894\n",
       "7    121.0  0.123409\n",
       "8    133.0  0.153398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference kt: 0.11699029126213592\n",
      "Training data shape, X_train.shape (1375, 5, 136) Y_train.shape torch.Size([1375, 5])\n",
      "set_and_load_data in LTREvaluator\n",
      "(1375, 5, 136) torch.Size([1375, 5]) (1375,)\n",
      "data_dict {'data_id': 'MODIFIED_MSLR_WEB10K', 'dir_data': 'data/MSLR-WEB10K/processed/default', 'min_docs': 10, 'min_rele': 1, 'scale_data': False, 'scaler_id': None, 'scaler_level': None, 'train_presort': True, 'validation_presort': True, 'test_presort': True, 'train_batch_size': 64, 'validation_batch_size': 1, 'test_batch_size': 1, 'unknown_as_zero': False, 'binary_rele': False, 'num_features': 136, 'has_comment': False, 'label_type': <LABEL_TYPE.Permutation: 2>, 'max_rele_level': None, 'fold_num': 1}\n",
      "data_dict {'data_id': 'MODIFIED_MSLR_WEB10K', 'dir_data': 'data/MSLR-WEB10K/processed/default', 'min_docs': 10, 'min_rele': 1, 'scale_data': False, 'scaler_id': None, 'scaler_level': None, 'train_presort': True, 'validation_presort': True, 'test_presort': True, 'train_batch_size': 64, 'validation_batch_size': 1, 'test_batch_size': 1, 'unknown_as_zero': False, 'binary_rele': False, 'num_features': 136, 'has_comment': False, 'label_type': <LABEL_TYPE.Permutation: 2>, 'max_rele_level': None, 'fold_num': 1}\n",
      "Sequential(\n",
      "  (FeatureBN): BatchNorm1d(136, eps=1e-05, momentum=1.0, affine=True, track_running_stats=False)\n",
      "  (L_1): Linear(in_features=136, out_features=30, bias=True)\n",
      "  (BN_1): BatchNorm1d(30, eps=1e-05, momentum=1.0, affine=True, track_running_stats=False)\n",
      "  (ACT_1): ReLU()\n",
      "  (DR_2): Dropout(p=0.01, inplace=False)\n",
      "  (L_2): Linear(in_features=30, out_features=30, bias=True)\n",
      "  (BN_2): BatchNorm1d(30, eps=1e-05, momentum=1.0, affine=True, track_running_stats=False)\n",
      "  (ACT_2): ReLU()\n",
      "  (L_3): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n",
      "epoch 0, loss [1103.4369], train tau 0.2481454610824585, test_tau 0.38810020685195923,train_ndcg@1 tensor([0.7840]), test_ndcg@1 tensor([0.7156])train_p@1 tensor([0.9716]), test_p@1, tensor([0.7474])\n",
      "epoch 1, loss [1027.4617], train tau 0.23650860786437988, test_tau 0.386221319437027,train_ndcg@1 tensor([0.7949]), test_ndcg@1 tensor([0.7203])train_p@1 tensor([0.9753]), test_p@1, tensor([0.7474])\n",
      "epoch 2, loss [997.27014], train tau 0.23127210140228271, test_tau 0.3824634552001953,train_ndcg@1 tensor([0.8029]), test_ndcg@1 tensor([0.7286])train_p@1 tensor([0.9738]), test_p@1, tensor([0.7265])\n",
      "epoch 3, loss [977.1213], train tau 0.2244357168674469, test_tau 0.3772442936897278,train_ndcg@1 tensor([0.8107]), test_ndcg@1 tensor([0.7307])train_p@1 tensor([0.9731]), test_p@1, tensor([0.7182])\n",
      "epoch 4, loss [970.8651], train tau 0.2215997576713562, test_tau 0.3770354986190796,train_ndcg@1 tensor([0.8122]), test_ndcg@1 tensor([0.7422])train_p@1 tensor([0.9775]), test_p@1, tensor([0.7223])\n",
      "epoch 5, loss [954.40027], train tau 0.21672692894935608, test_tau 0.3768267035484314,train_ndcg@1 tensor([0.8204]), test_ndcg@1 tensor([0.7307])train_p@1 tensor([0.9760]), test_p@1, tensor([0.7265])\n",
      "epoch 6, loss [947.0547], train tau 0.21789047122001648, test_tau 0.37578287720680237,train_ndcg@1 tensor([0.8191]), test_ndcg@1 tensor([0.7296])train_p@1 tensor([0.9738]), test_p@1, tensor([0.7349])\n",
      "epoch 7, loss [937.74664], train tau 0.21221759915351868, test_tau 0.37473902106285095,train_ndcg@1 tensor([0.8255]), test_ndcg@1 tensor([0.7270])train_p@1 tensor([0.9745]), test_p@1, tensor([0.7119])\n",
      "epoch 8, loss [920.88446], train tau 0.20203545689582825, test_tau 0.3774530291557312,train_ndcg@1 tensor([0.8315]), test_ndcg@1 tensor([0.7161])train_p@1 tensor([0.9804]), test_p@1, tensor([0.7035])\n",
      "epoch 9, loss [907.0977], train tau 0.20567134022712708, test_tau 0.37515658140182495,train_ndcg@1 tensor([0.8302]), test_ndcg@1 tensor([0.7093])train_p@1 tensor([0.9767]), test_p@1, tensor([0.7203])\n",
      "The experiment result is saved in ../../tmp/results/MSLR-WEB10K/default/result_summary.pkl\n"
     ]
    }
   ],
   "source": [
    "for seed in range(5, 10):\n",
    "    \n",
    "    save_path = os.path.join(root_path, 'data/MSLR-WEB10K/True_5')\n",
    "    file_train = 'train.npz'\n",
    "    file_test = 'test.npz'\n",
    "\n",
    "    train = np.load(os.path.join(save_path, file_train))\n",
    "    test = np.load(os.path.join(save_path, file_test))\n",
    "    X_train, Y_train, qid_train = train['X'], train['Y'], train['qid']\n",
    "    X_test, Y_test, qid_test = test['X'], test['Y'], test['qid']\n",
    "\n",
    "    # Weak supervision\n",
    "    d = X_train.shape[1]\n",
    "    r_utils = RankingUtils(d)\n",
    "    dummy_lf = FeatureRankingLF(rank_on_feature=0, d=d, highest_first=False)\n",
    "    true_ranking = dummy_lf.apply_mat(np.concatenate((np.expand_dims(Y_train, axis=-1), np.expand_dims(Y_test, axis=-1))))\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    feature_list = [0, 5, 95, 101, 106, 111, 116, 121, 133]\n",
    "    L_ = []\n",
    "    for feature in feature_list:\n",
    "        lf = FeatureRankingLF(rank_on_feature=feature, d=d, highest_first=True)\n",
    "        wl = lf.apply_mat(np.concatenate((X_train, X_test)))\n",
    "        kt = r_utils.mean_kt_distance(true_ranking, wl)\n",
    "        df = df.append(\n",
    "        {\n",
    "            'feature': feature,\n",
    "            'kt': kt\n",
    "        }, ignore_index=True)\n",
    "        L_.append(wl)\n",
    "\n",
    "    display(df)\n",
    "\n",
    "    L = []\n",
    "    for data_idx in range(len(L_[0])):\n",
    "        L_row = []\n",
    "        for wl_idx in range(len(L_)):\n",
    "            L_row.append(L_[wl_idx][data_idx])\n",
    "        L.append(L_row)\n",
    "\n",
    "    wsr = WeakSupRanking(r_utils)\n",
    "    wsr.train(weak_sup_conf, L)\n",
    "\n",
    "    m = len(L[0])\n",
    "    lst_pi_hat = wsr.infer_ranking(weak_sup_conf, L, numLFs=m)\n",
    "    kt = r_utils.mean_kt_distance(true_ranking, lst_pi_hat)\n",
    "    print('inference kt:', kt)\n",
    "    \n",
    "    ptwrapper = PtrankingWrapper(data_conf=data_conf, weak_sup_conf=weak_sup_conf,\n",
    "                                 l2r_training_conf=l2r_training_conf, result_path=conf['results_path'],\n",
    "                                 wl_kt_distance = kt)\n",
    "\n",
    "    Y_train = ranking_to_score(lst_pi_hat, d=d, highest_first=False)[:X_train.shape[0]]\n",
    "    ptwrapper.set_data(X_train=X_train, X_test=X_test,\n",
    "                      Y_train=Y_train, Y_test=Y_test)\n",
    "    model = ptwrapper.get_model()\n",
    "    result = ptwrapper.train_model(model, IR=True, verbose=1)\n",
    "    result_path = f'results/Selected_{seed}.pickle'\n",
    "    with open(result_path, 'wb') as f:\n",
    "        pickle.dump(result, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws-cardinality",
   "language": "python",
   "name": "ws-cardinality"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
