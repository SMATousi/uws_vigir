{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "complete-capital",
   "metadata": {},
   "source": [
    "# Path setup & import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "packed-seminar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "root_path = '../../../' # path to project root\n",
    "sys.path.append('{}/code'.format(root_path))\n",
    "sys.path.append('{}/code/core'.format(root_path))\n",
    "sys.path.append('{}/code/datasets/'.format(root_path))\n",
    "sys.path.insert(0,'{}/code/ptranking'.format(root_path))\n",
    "\n",
    "from core.ranking_utils import *\n",
    "from core.mallows import *\n",
    "from core.ws_ranking import *\n",
    "from core.ws_real_workflow import * \n",
    "from datasets.imdb_tmdb_dataset import * \n",
    "from datasets.basic_clmn_dataset import * \n",
    "from core.labelling.feature_lf import *\n",
    "from ptranking_wrapper import PtrankingWrapper\n",
    "import datasets_factory \n",
    "import numpy as np \n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "label_feature = 'vote_average'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-newcastle",
   "metadata": {},
   "source": [
    "# Read config & basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "agreed-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = '{}/configs/imdb-tmdb_ranking_experiment_play.yaml'.format(root_path)\n",
    "\n",
    "with open(config_file_path,'r') as conf_file:\n",
    "    conf = yaml.full_load(conf_file)\n",
    "    conf['project_root'] = root_path \n",
    "\n",
    "data_conf = conf['data_conf']\n",
    "weak_sup_conf = conf['weak_sup_conf'] # For partial ranking experiments, we should give\n",
    "l2r_training_conf = conf['l2r_training_conf']\n",
    "data_conf['project_root'] = root_path\n",
    "d = data_conf['dimension']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "attached-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_sup_conf['synthetic'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-antarctica",
   "metadata": {},
   "source": [
    "# Dataset sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "spatial-edinburgh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate samples...\n"
     ]
    }
   ],
   "source": [
    "dataset= datasets_factory.create_dataset(data_conf)\n",
    "dataset.create_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "provincial-alexandria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['count_production_countries',\n",
       " 'year',\n",
       " 'count_spoken_langueges',\n",
       " 'num_critic_for_reviews',\n",
       " 'duration',\n",
       " 'director_facebook_likes',\n",
       " 'gross',\n",
       " 'num_voted_users',\n",
       " 'cast_total_facebook_likes',\n",
       " 'facenumber_in_poster',\n",
       " 'num_user_for_reviews',\n",
       " 'budget_imdb',\n",
       " 'title_year',\n",
       " 'aspect_ratio',\n",
       " 'movie_facebook_likes',\n",
       " 'budget_tmdb',\n",
       " 'popularity',\n",
       " 'revenue',\n",
       " 'runtime',\n",
       " 'vote_count',\n",
       " 'actor_facebook_likes']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = data_conf['features']\n",
    "nonbinary_features = []\n",
    "\n",
    "df = pd.read_csv(os.path.join(root_path, 'data',\n",
    "                              'imdb-tmdb', 'merged_imdb_tmdb_with_additional_features.csv')).fillna(0)\n",
    "for feature in feature_list:\n",
    "    if (len(df[feature].unique()) > 3) and (feature != label_feature):\n",
    "        nonbinary_features.append(feature)\n",
    "nonbinary_features    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "planned-poultry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_production_countries kt distance:  0.4843333333333333\n",
      "year kt distance:  0.5539999999999999\n",
      "count_spoken_langueges kt distance:  0.4633333333333333\n",
      "num_critic_for_reviews kt distance:  0.4021666666666666\n",
      "duration kt distance:  0.3703333333333333\n",
      "director_facebook_likes kt distance:  0.4471666666666666\n",
      "gross kt distance:  0.44966666666666666\n",
      "num_voted_users kt distance:  0.3535\n",
      "cast_total_facebook_likes kt distance:  0.4766666666666667\n",
      "facenumber_in_poster kt distance:  0.5265\n",
      "num_user_for_reviews kt distance:  0.3926666666666667\n",
      "budget_imdb kt distance:  0.5001666666666668\n",
      "title_year kt distance:  0.5529999999999999\n",
      "aspect_ratio kt distance:  0.48849999999999993\n",
      "movie_facebook_likes kt distance:  0.4506666666666666\n",
      "budget_tmdb kt distance:  0.4848333333333334\n",
      "popularity kt distance:  0.39633333333333337\n",
      "revenue kt distance:  0.42799999999999994\n",
      "runtime kt distance:  0.358\n",
      "vote_count kt distance:  0.385\n",
      "actor_facebook_likes kt distance:  0.4751666666666667\n"
     ]
    }
   ],
   "source": [
    "wl_feature_list = []\n",
    "for feature in nonbinary_features:\n",
    "    wl = []\n",
    "    lf = FeatureRankingLF(feature, d=d, highest_first=True)\n",
    "    for row in dataset.lst_feature_map:\n",
    "        wl.append(lf.apply(row))\n",
    "    kt = r_utils.mean_kt_distance(wl, dataset.Y)\n",
    "    print(feature, 'kt distance: ', kt)\n",
    "    if kt < 0.375:\n",
    "        wl_feature_list.append(feature)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "listed-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_feature_list = [\n",
    " 'num_critic_for_reviews',\n",
    " 'budget_tmdb',\n",
    " 'popularity',\n",
    " 'revenue',\n",
    " 'runtime']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-radar",
   "metadata": {},
   "source": [
    "# Label model learning & inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "iraqi-chassis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weak labels generated and saved in ../../../data/imdb-tmdb/processed/210513_dim-10_ntrain-500_ntest-1000_model-ListMLE_weaklabel-False/LFs/weak_labels.pkl\n",
      "Use our weak supervision...train_method: triplet_opt,inference_rule: weighted_kemeny\n",
      "kt distance:  0.4026666666666667\n"
     ]
    }
   ],
   "source": [
    "if l2r_training_conf['use_weak_labels']:\n",
    "    Y_tilde, thetas = get_weak_labels(dataset, weak_sup_conf, root_path=root_path)\n",
    "    r_utils = RankingUtils(data_conf['dimension'])\n",
    "    kt = r_utils.mean_kt_distance(Y_tilde,dataset.Y)\n",
    "    print('kt distance: ', kt)\n",
    "    dataset.set_Y_tilde(Y_tilde)\n",
    "else:\n",
    "    kt = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-jersey",
   "metadata": {},
   "source": [
    "# Train and evaluation - mainly with PtrankingWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "relative-press",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_weak_labels:True, we will use weak labels\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6bd7192bbbf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                              \u001b[0ml2r_training_conf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2r_training_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'results_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                              wl_kt_distance = kt)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_train_test_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_weak_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2r_training_conf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'use_weak_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m ptwrapper.set_data(X_train=X_train, X_test=X_test,\n\u001b[1;32m      6\u001b[0m                   Y_train=Y_train, Y_test=Y_test)\n",
      "\u001b[0;32m~/universalizing-weak-supervision/code/datasets/imdb_tmdb_dataset.py\u001b[0m in \u001b[0;36mget_train_test_torch\u001b[0;34m(self, use_weak_labels)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_weak_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# use weak label for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"use_weak_labels:{use_weak_labels}, we will use weak labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ranking_to_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_tilde\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"use_weak_labels:{use_weak_labels}, we will use true labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/universalizing-weak-supervision/code/datasets/imdb_tmdb_dataset.py\u001b[0m in \u001b[0;36m_ranking_to_score\u001b[0;34m(self, Y, highest_first)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mY_score_torch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mranking_to_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhighest_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mY_score_torch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "ptwrapper = PtrankingWrapper(data_conf=data_conf, weak_sup_conf=weak_sup_conf,\n",
    "                             l2r_training_conf=l2r_training_conf, result_path=conf['results_path'],\n",
    "                             wl_kt_distance = kt)\n",
    "X_train, X_test, Y_train, Y_test = dataset.get_train_test_torch(use_weak_labels=l2r_training_conf['use_weak_labels'])\n",
    "ptwrapper.set_data(X_train=X_train, X_test=X_test,\n",
    "                  Y_train=Y_train, Y_test=Y_test)\n",
    "model = ptwrapper.get_model()\n",
    "result = ptwrapper.train_model(model, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-blade",
   "metadata": {},
   "source": [
    "# Training log visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = '24'\n",
    "losses = result['loss']\n",
    "train_tau = result['train_tau']\n",
    "test_tau = result['test_tau']\n",
    "train_ndcg1 = result['train_ndcg1']\n",
    "train_ndcg3 = result['train_ndcg3']\n",
    "train_ndcg5 = result['train_ndcg5']\n",
    "test_ndcg1 = result['test_ndcg1']\n",
    "test_ndcg3 = result['test_ndcg3']\n",
    "test_ndcg5 = result['test_ndcg5']\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(16,9))\n",
    "axes[0].plot(losses)\n",
    "axes[0].set_title(f'Training loss', fontsize=22)\n",
    "axes[1].plot(train_tau, label='train_mean_kt')\n",
    "axes[1].plot(test_tau, label='test_mean_kt')\n",
    "axes[1].set_ylim(0,1)\n",
    "axes[1].legend(fontsize=18)\n",
    "axes[1].set_title(f'Kendall Tau', fontsize=22)\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(16,9))\n",
    "axes[0].plot(train_ndcg1, label='NDCG@1')\n",
    "axes[0].plot(train_ndcg3, label='NDCG@3')\n",
    "axes[0].plot(train_ndcg5, label='NDCG@5')\n",
    "axes[0].legend()\n",
    "axes[0].set_title(f'Train NDCG', fontsize=22)\n",
    "axes[1].plot(test_ndcg1, label='NDCG@1')\n",
    "axes[1].plot(test_ndcg3, label='NDCG@3')\n",
    "axes[1].plot(test_ndcg5, label='NDCG@5')\n",
    "axes[1].set_title(f'Test NDCG', fontsize=22)\n",
    "axes[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-pressure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-latino",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-trustee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-drinking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-possession",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-abortion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws-cardinality",
   "language": "python",
   "name": "ws-cardinality"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
