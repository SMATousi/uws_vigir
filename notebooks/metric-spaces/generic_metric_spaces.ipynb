{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Metric Space Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import os\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a random graph\n",
    "\n",
    "Let's pick a random graph and get the distance matrix for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, num_edges = 10, 20\n",
    "\n",
    "# get a connected graph\n",
    "G = nx.gnm_random_graph(n, num_edges)\n",
    "while not nx.is_connected(G):\n",
    "    G = nx.gnm_random_graph(n, num_edges)\n",
    "\n",
    "D = nx.floyd_warshall_numpy(G)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in G.adjacency():\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities for model\n",
    "\n",
    "Next some brute-force utilities that give us the probabilities for a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition_function(D, theta, center):\n",
    "    tot = 0.0\n",
    "    for i in range(D.shape[0]):\n",
    "        tot += np.exp(-theta*D[center, i])\n",
    "    return tot\n",
    "\n",
    "def prob(center, x, Z, theta):\n",
    "    return np.exp(-theta*D[center, x])/Z\n",
    "\n",
    "def get_weighted_center(points, weights, D):\n",
    "    mindist = 10**10\n",
    "    curridx = -1\n",
    "    \n",
    "    for i in range(D.shape[0]):\n",
    "        currdist = 0.0\n",
    "        for point, weight in zip(points, weights):\n",
    "            currdist += weight * D[point, i]**2\n",
    "        if currdist <= mindist:\n",
    "            curridx = i\n",
    "            mindist = currdist\n",
    "    \n",
    "    return curridx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging to make sure everything works: compute partition function, show that the probabilities are well-defined, see if we recover the correct central node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 2.0\n",
    "Z = get_partition_function(D, theta, 0)\n",
    "print(f\"Probability of seeing node 0 when node 0 is the center is {prob(0,0,Z, theta)}\")\n",
    "\n",
    "t = 0.0\n",
    "for i in range(n):\n",
    "    t += prob(0, i, Z, theta)\n",
    "print(f\"This should be 1 {t}\")\n",
    "\n",
    "get_weighted_center(np.array(range(n)), np.ones(n), D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(D, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ws_loop_mv(n, m, thetas, D):\n",
    "    # pick a random y:\n",
    "    y = np.random.randint(0, n)\n",
    "\n",
    "    # generate the LFs:\n",
    "    Zy = get_partition_function(D, theta, y)\n",
    "    lfs = np.zeros(m)\n",
    "    for j in range(m):\n",
    "        probs = np.zeros(n)\n",
    "        for k in range(n):\n",
    "            probs[k] = prob(y, k, Zy, thetas[j])\n",
    "        # since sometimes this is 0.999 \n",
    "        probs /= np.sum(probs)\n",
    "\n",
    "        lfs[j] = np.random.choice(n, 1, p=probs)\n",
    "\n",
    "    lfs = lfs.astype(int)\n",
    "    # recover from the LFs\n",
    "    yhat = get_weighted_center(lfs, np.ones(m), D)\n",
    "\n",
    "    if y == yhat:\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def estimate_thetas(distab, distac, distbc):\n",
    "    return 2.0 / (distab + distac - distbc)\n",
    "\n",
    "def ws_loop_full(n, m, thetas, D, samples):\n",
    "    # generate the data first:\n",
    "    ys, yhat, yhat_mv = np.zeros(samples).astype(int), np.zeros(samples), np.zeros(samples)\n",
    "    lfs = np.zeros((samples, m))\n",
    "    corr, corr_mv = 0, 0\n",
    "\n",
    "    for i in range(samples):\n",
    "        ys[i] = np.random.randint(0, n)\n",
    "\n",
    "        # generate the LFs:\n",
    "        Zy = get_partition_function(D, theta, ys[i])\n",
    "        for j in range(m):\n",
    "            probs = np.zeros(n)\n",
    "            for k in range(n):\n",
    "                probs[k] = prob(ys[i], k, Zy, thetas[j])\n",
    "            # since sometimes this is 0.999 \n",
    "            probs /= np.sum(probs)\n",
    "\n",
    "            lfs[i, j] = np.random.choice(n, 1, p=probs)\n",
    "\n",
    "    lfs = lfs.astype(int)\n",
    "\n",
    "    # learn label model\n",
    "    theta_hat = np.zeros(m)\n",
    "    dists_true = np.zeros(m)\n",
    "    triplet_runs = 5 # probably should change this\n",
    "    for j in range(m):\n",
    "        lf_indices = list(range(m))\n",
    "        lf_indices.remove(j)    \n",
    "        triplets = list(itertools.combinations(lf_indices, 2))\n",
    "        theta_est = np.zeros(triplet_runs)\n",
    "\n",
    "        # true distance to y:\n",
    "        for i in range(samples):\n",
    "            dists_true[j] += D[lfs[i, j], ys[i]]\n",
    "                \n",
    "        for run in range(triplet_runs):\n",
    "            b, c = triplets[run]\n",
    "            dab, dac, dbc = 0.0, 0.0, 0.0\n",
    "            for i in range(samples):\n",
    "                dab += D[lfs[i, j], lfs[i, b]]\n",
    "                dac += D[lfs[i, j], lfs[i, c]]\n",
    "                dbc += D[lfs[i, b], lfs[i, c]]\n",
    "            dab /= samples\n",
    "            dac /= samples\n",
    "            dbc /= samples\n",
    "            theta_est[run] += estimate_thetas(dab, dac, dbc)\n",
    "        theta_hat[j] = np.median(theta_est)\n",
    "    dists_true /= samples\n",
    "    #print(f\"true distances = {dists_true}\") # DEBUG: show the true average distances    \n",
    "    #print(f\"theta_hat = {theta_hat}\") # DEBUG: show the recovered theta parameters\n",
    "\n",
    "    # predict based on label model or majority vote\n",
    "    for i in range(samples):\n",
    "        yhat_mv[i] = get_weighted_center(lfs[i, :], 1.0 * theta_hat, D)\n",
    "        yhat[i] = get_weighted_center(lfs[i, :], np.ones(m), D)\n",
    "        if ys[i] == yhat[i]:\n",
    "            corr += 1\n",
    "        if ys[i] == yhat_mv[i]:\n",
    "            corr_mv += 1\n",
    "\n",
    "    return corr/samples, corr_mv/samples\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority Vote Experiment\n",
    "\n",
    "Now let's generate some LFs with the same distance and see what happens. \n",
    "\n",
    "Expected: the curve goes up as the $\\theta$ paramater increases, since the LFs become higher and higher quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 LFs with the same values of theta\n",
    "m = 10\n",
    "theta_vals = [0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "samples = 100\n",
    "\n",
    "accs = np.zeros(len(theta_vals))\n",
    "\n",
    "for theta_val, v in zip(theta_vals, list(range(len(theta_vals)))):\n",
    "    thetas = theta_val * np.ones(m)\n",
    "    corr = 0\n",
    "    for i in range(samples):\n",
    "        corr += ws_loop_mv(n, m, thetas, D)\n",
    "    accs[v] = corr/samples\n",
    "\n",
    "plt.plot(theta_vals, accs, marker='o')\n",
    "plt.grid()\n",
    "plt.xlabel('Theta parameter')\n",
    "plt.ylabel('Majority Vote Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MV + LM Experiment\n",
    "Next let's see if things change as the thetas are different. Can we make the LM better?\n",
    "\n",
    "We'll run some alternating-quality LFs (one gets a good $\\theta$, one a bad $\\theta$). We also run multiple runs where the overall average $\\theta$ increases, so both curves shuold go up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10\n",
    "\n",
    "\n",
    "# a set of values of theta from very bad (highly inaccurate) to very good (highly accurate)\n",
    "theta_vals = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5]\n",
    "samples = 1000\n",
    "\n",
    "accs_mv, accs = np.zeros(len(theta_vals)), np.zeros(len(theta_vals))\n",
    "thetas_mean = []\n",
    "for theta_val, v in zip(theta_vals, list(range(len(theta_vals)))):\n",
    "    # this one sets alternating quality LFs\n",
    "    thetas = theta_val * ((np.array(list(range(m))) % 2).astype(float) + 0.1*v)\n",
    "    thetas_mean.append(np.mean(thetas))\n",
    "\n",
    "    \n",
    "    #print(f\"true thetas = f{thetas}\") # DEBUG: check the true thetas and the relative recovery order\n",
    "    accs_mv[v], accs[v] = ws_loop_full(n, m, thetas, D, samples)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heterogenous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams['font.size'] = '34'\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "\n",
    "ax.plot(thetas_mean, accs_mv, marker='o', markersize=14, linewidth=4)\n",
    "ax.plot(thetas_mean, accs, marker='x',  markersize=14, linewidth=4)\n",
    "ax.legend(['Majority Vote', 'Label Model'], fontsize=22)\n",
    "ax.grid()\n",
    "ax.set_xlabel('Theta average')\n",
    "ax.set_ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homogenous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10\n",
    "\n",
    "# a set of values of theta from very bad (highly inaccurate) to very good (highly accurate)\n",
    "theta_vals = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]\n",
    "samples = 1000\n",
    "\n",
    "accs_mv, accs = np.zeros(len(theta_vals)), np.zeros(len(theta_vals))\n",
    "thetas_mean = []\n",
    "for theta_val, v in zip(theta_vals, list(range(len(theta_vals)))):\n",
    "\n",
    "    # this one sets equal quality LFs\n",
    "    thetas = theta_val * np.ones(m)\n",
    "    thetas_mean.append(np.mean(thetas))\n",
    "\n",
    "    #print(f\"true thetas = f{thetas}\") # DEBUG: check the true thetas and the relative recovery order\n",
    "    accs_mv[v], accs[v] = ws_loop_full(n, m, thetas, D, samples)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "plt.rcParams['font.size'] = '34'\n",
    "ax.plot(thetas_mean, accs_mv, marker='o', markersize=14, linewidth=4)\n",
    "ax.plot(thetas_mean, accs, marker='x',  markersize=14, linewidth=4)\n",
    "ax.legend(['Majority Vote', 'Label Model'], fontsize=22)\n",
    "ax.grid()\n",
    "ax.set_xlabel('Theta average')\n",
    "ax.set_ylabel('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75e1510848ff81b2a8a3022c3bfac472ed28a49a56e1422a056d525171f2408b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
